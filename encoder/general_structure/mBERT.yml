# mBERT.yaml
model_name_or_path: google-bert/bert-base-multilingual-cased
train_path: "data/tibetan_verses_vs_prose_train_unicode_600.csv"
test_path: "data/tibetan_verses_vs_prose_test_unicode_400.csv"
text_column: text
label_column: task_1_label


task_name: verses_prose
task: classification

seed: [42,0,1,32,52]

train_batch_size: 16
eval_batch_size: 16
max_length: 512

learning_rate: 5e-5
weight_decay: 0.0
num_train_epochs: 6

save_strategy: epoch
eval_steps: 200
save_steps: 200
logging_steps: 1000

load_best_model_at_end: false
metric_for_best_model: f1
greater_is_better: true

report_to: []
fp16: false

